[["index.html", "Introduction to Optimization Preface", " Introduction to Optimization Apurva Nakade 2022-05-04 Preface "],["introduction.html", "Chapter 1 Introduction 1.1 Software tools", " Chapter 1 Introduction The question of optimization is the very general question of deciding when a function \\(f(x_1, \\dots, x_n)\\) attains its maximum or minimum value on a domain \\(D\\) in \\(\\mathbb{R^n}\\). \\[\\begin{align} \\mbox{optimize: } &amp;&amp; f(x_1, \\dots, x_n) &amp; \\\\ \\mbox{subject to: } &amp;&amp; (x_1, \\dots, x_n) &amp;\\in D. \\end{align}\\] These kinds questions show up naturally in every quantitative field. To analyze the question meaningfully, one needs to make some assumptions on \\(f\\) and \\(D\\). In this course, we’ll analyze this question in the special case when the function \\(f\\) is linear and the constraint set \\(D\\) is described using linear inequalities. The study of this problem is called Linear Programming. Despite the simplicity of the Linear Programming setup, or perhaps because of it, LP is one of the most commonly used models for optimization problems. We’ll see how to solve linear programs using the simplex method and go on to analyze the solution sets using duality theory. Linear programs are used for modeling real world problems when prices/costs and constraints are fixed and known beforehand. Even when this is not the case, linear programs are often used to approximate and estimate costs/prices before moving on to more sophisticated techniques. Example 1.1 A bond portfolio manager has $100,000 to allocate to two different bonds; one corporate and one government bond. The corporate bond has a yield of 4%, a maturity of 3 years and an A rating from a rating agency that is translated into a numerical rating of 2 for computational purposes. In contrast, the government bond has a yield of 3%, a maturity of 6 years and rating of Aaa with the corresponding numerical rating of 1 (lower numerical ratings correspond to higher quality bonds). The portfolio manager would like to allocate her funds so that the average rating for the portfolio is no worse than Aa (numerical equivalent 1.5) and average maturity of the portfolio is at most 3.6 years. Any amount not invested in the two bonds will be kept in a cash account that is assumed to earn no interest for simplicity and does not contribute to the average rating or maturity computations. How should the manager allocate her funds between these two bonds to achieve her objective of maximizing the annual yield from this investment? (Cornuéjols, Peña, and Tütüncü 2018) Corporate Government Bounds Yield 4% 3% Maturity 3 6 3.6 Rating A = 2 Aaa = 1 1.5 Fund Allocations ?? ?? 100,000 Solution We can model the above problem as follows: \\[\\begin{equation} \\begin{array}{rrrrrr} \\mbox{maximize:} &amp; 4x &amp; + &amp; 3y \\\\ \\mbox{subject to:} &amp; 3x &amp; + &amp; 6y &amp; \\le &amp; 3.6 \\\\ &amp; 2x &amp; + &amp; y &amp; \\le &amp; 1.5 % &amp; x &amp; + &amp; y &amp; \\le &amp; 1 \\\\ % &amp; x &amp; , &amp; y &amp; \\ge &amp; 0, \\end{array} \\tag{1.1} \\end{equation}\\] where \\(x\\), \\(y\\) are the percentages of corporate and government bonds, respectively, and the objective function when multiplied by $100,000 gives us the net yield. This is an example of a linear program. Note that we cannot subtract inequalities the same way that we can subtract equalities. So to get started, let us assume that both the inequalities are in fact equalities. We can solve the system \\[\\begin{equation} \\begin{array}{rrrrrl} &amp; 3x &amp; + &amp; 6y &amp; = &amp; 3.6 \\\\ &amp; 2x &amp; + &amp; y &amp; = &amp; 1.5 \\end{array} \\end{equation}\\] to obtain \\(x = 0.6\\) and \\(y = 0.3\\). But for this solution \\(x + y = 0.9\\) which is less that 1, meaning that we’re not investing all the available funds! Which raises the question: Is it possible to increase the yield further by not satisfying both of the above equalities and investing all the money instead? This question becomes even more apparent once we realize that the linear program (1.1) is incomplete and the complete linear program that models the problem is as follows: \\[\\begin{equation} \\begin{array}{rrrrrl} \\mbox{maximize:} &amp; 4x &amp; + &amp; 3y \\\\ \\mbox{subject to:} &amp; 3x &amp; + &amp; 6y &amp; \\le &amp; 3.6 \\\\ &amp; 2x &amp; + &amp; y &amp; \\le &amp; 1.5 \\\\ &amp; x &amp; + &amp; y &amp; \\le &amp; 1 \\\\ &amp; x &amp; &amp; &amp; \\ge &amp; 0 \\\\ &amp; &amp; &amp; y &amp; \\ge &amp; 0. \\end{array} \\tag{1.2} \\end{equation}\\] The solution \\((x, y) = (0.6, 0.3)\\) is obtained by changing the first two inequalities to equalities. But this choice is completely arbitrary! We could have switched some other set of inequalities to equalities and obtained a different solution. We’d then need to compare the solutions obtained in each of these cases and find the one that maximizes it. This method becomes unwieldy very fast and we’ll need to develop better ways to solve linear programs. 1.1 Software tools 1.1.1 Graphing calculator Linear programs in two variables can be visualized using a graphing calculator. The constraints in Example 1.1 can be visualized as follows: The feasible set is the quadrilateral formed by the overlap of all three constraint regions. The level sets of the objective function are straight lines of the form \\(4x + 3y = c\\). We can use a graphical calculator to find the largest value of \\(c\\) for which these level sets intersect the feasible region, which turns out to be \\(c = 3.3\\%\\) which gives us a net yield of \\(3.3\\% \\times \\$100,000 = \\$3,300\\). Here is the same picture in Desmos: https://www.desmos.com/calculator/bexwrrcbwx As it turns out, there is no efficient way to implement this method purely algebraically, thereby making it unusable in higher dimensions. 1.1.2 Solver add-in Excel and Google sheets have free, easy-to-use linear program solvers that can be used to solve linear programs and generate sensitivity analysis. Here is a sample solution of Example 1.1 using Solver in Excel: https://1drv.ms/x/s!AnwQOvs0HXuihl3PWf5YQLWsF6qB?e=rddRBy References "],["standard-linear-program.html", "Chapter 2 Standard linear program 2.1 Slack variables 2.2 Basic and non-basic variables", " Chapter 2 Standard linear program A standard linear program is an optimization problem of the following form: \\[\\begin{equation} \\begin{array}{lrrrrrrrrr} \\mbox{maximize: } &amp; c_0 &amp; + &amp; c_1 x_1 &amp; + &amp; \\dots &amp; + &amp; c_n x_n &amp; \\\\ \\mbox{subject to: } &amp; &amp; &amp; a_{11} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{1n} x_n &amp; \\leq &amp; b_1 \\\\ &amp; &amp; &amp; a_{21} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{2n} x_n &amp; \\leq &amp; b_2 \\\\ &amp; &amp; &amp; &amp; &amp; \\vdots &amp; \\\\ &amp; &amp; &amp; a_{m1} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{mn} x_n &amp; \\leq &amp; b_m \\\\ &amp; &amp; &amp; x_1, &amp; x_2, &amp; \\dots &amp;, &amp; x_n &amp; \\geq &amp; 0 \\end{array} \\tag{2.1} \\end{equation}\\] where \\(c_i\\), \\(a_{ij}\\), and \\(b_j\\) are real constants. The variables \\(x_1, \\dots, x_n\\) are called decision variables. The set of tuples \\((x_1, \\dots, x_n)\\) that satisfy all the constraints is called the feasible region. Example 2.1 Equation (1.2) is an example of a standard linear program with 2 decision variables, 3 constraints, and the feasible region being a quadrilateral. Remark. Not every linear program is standard. However, we will see later that every linear program can be standardized and hence it suffices to construct an algorithm for solving standard linear programs. We’ll assume the following two theorems without proof for now: Theorem 2.1 The feasible region of a standard linear program is either empty, or a convex polytope (possibly degenerate or infinite) . The precise definition of a convex polytope is quite complicated. For the purposes of this class, it is sufficient to think of a polytope as a region that has vertices and edges. Theorem 2.2 Every standard linear program attains its optimal solution, if any, at one of the vertices of the feasible region. Note that the above theorem claims neither the existence nor the uniqueness of an optimal solution. All it is saying is that if a maximum objective value exists then it is attained at one of the vertices. It is possible that no optimal value exists or that the optimal value is attained more than one points, possible at a non-vertex. 2.1 Slack variables For each constraint, we introduce a slack variable by subtracting the LHS from the RHS as follows. \\[\\begin{equation} \\begin{array}{lrrrrrrrrr} w_1 &amp; = &amp; b_1 &amp; - &amp; a_{11} x_1 &amp; - &amp; \\dots &amp; - &amp; a_{1n} x_n \\\\ w_2 &amp; = &amp; b_2 &amp; - &amp; a_{21} x_1 &amp; - &amp; \\dots &amp; - &amp; a_{2n} x_n \\\\ &amp; &amp; &amp; &amp; &amp; \\vdots &amp; \\\\ w_m &amp; = &amp; b_m &amp; - &amp; a_{m1} x_1 &amp; - &amp; \\dots &amp; - &amp; a_{mn} x_n \\end{array} \\tag{2.2} \\end{equation}\\] We can think of the slack variable \\(w_i\\) as measuring the “slackness” in the \\(i^{th}\\) constraint. The \\(i^{th}\\) constraint is strictly met exactly when \\(w_i\\) is zero. Using the slack variables, the linear program (2.1) can be succinctly rewritten as: \\[\\begin{equation} w_1, \\dots, w_m, x_1, \\dots, x_n \\geq 0. \\end{equation}\\] Example 2.2 The slack variables for the linear program (1.2) are as follows: \\[\\begin{equation} \\begin{array}{rlllll} w_1 &amp; = &amp; 3.6 &amp; - &amp; 3x &amp; - &amp; 6y \\\\ w_2 &amp; = &amp; 1.5 &amp; - &amp; 2x &amp; - &amp; y \\\\ w_3 &amp; = &amp; 1 &amp; - &amp; x &amp; - &amp; y. \\end{array} \\end{equation}\\] In terms of these slack variables, the constraints can be rewritten as \\(x, y, w_1, w_2, w_3 \\ge 0\\) and the boundaries of the feasible region are given by \\(x = 0, y = 0, w_1 = 0, w_2 = 0, w_3 = 0\\). 2.2 Basic and non-basic variables Each vertex of the feasible region of a standard linear program in \\(n\\) variables is obtained by setting at least \\(n\\) variables (decision or slack) to zero. These variables are called non-basic and the remaining ones are called basic. Example 2.3 For the linear program (1.2), at the origin: the non-basic variables are \\(x, y\\) and the basic variables are \\(w_1, w_2, w_3\\), at the optimal solution: the non-basic variables are \\(w_1, w_2\\) and the basic variables are \\(x, y, w_3\\). Remark. Not every vertex obtained by setting \\(n\\) variables to zero is in the feasible region. For example, the vertex \\(x = 0, w_2 = 0\\) is not the in feasible region of the linear program (1.2). "],["simplex-method.html", "Chapter 3 Simplex method 3.1 Entering and leaving variables 3.2 Dictionaries 3.3 The simplex step 3.4 Stopping conditions", " Chapter 3 Simplex method The Simplex method is an iterative process for finding the optimal solution of a standard linear program. It starts at the some vertex of the feasible region and in each step moves to an adjacent vertex with a higher objective value. The following picture shows one possible run of the simplex algorithm for solving the linear program (1.2). Figure 3.1: A possible run of the simplex algorithm. 3.1 Entering and leaving variables In each step, one non-basic variable enters the set of basic variables and one basic variable leaves the set of basic variables. The table below explains how these sets are getting updated in the sample simplex algorithm run in Figure 3.1. Leaving variable Entering variable Basic variables Non-basic variables Start \\(\\{w_1, w_2, w_3\\}\\) \\(\\{x, y\\}\\) Step 1 \\(w_2\\) \\(x\\) \\(\\{w_1, x, w_3\\}\\) \\(\\{w_2, y\\}\\) Step 2 \\(w_1\\) \\(y\\) \\(\\{y, x, w_3\\}\\) \\(\\{w_2, w_1\\}\\) Our goal at each step is now reduced to figuring out the entering and leaving variables. 3.2 Dictionaries We’ll find the entering and leaving variables using dictionaries. A dictionary is a set of equations describing the objective function and the constraints in terms of the non-basic variables. Example 3.1 Consider (1.2) again. At the origin the non-basic variables are \\(x, y\\) and hence the initial dictionary is: \\[\\begin{equation} \\begin{array}{rlrrrr} \\mbox{objective} &amp; = &amp; 0 &amp; + &amp; 4x &amp; + &amp; 3y \\\\ w_1 &amp; = &amp; 3.6 &amp; - &amp; 3x &amp; - &amp; 6y \\\\ w_2 &amp; = &amp; 1.5 &amp; - &amp; 2x &amp; - &amp; y \\\\ w_3 &amp; = &amp; 1 &amp; - &amp; x &amp; - &amp; y. \\end{array} \\tag{3.1} \\end{equation}\\] After the first step of the simplex algorithm, the non-basic variables are \\(w_2, y\\). We can write \\(x\\) in terms of \\(w_2\\) to get \\[\\begin{equation} x = 0.75 - 0.5 w_2 - 0.5 y \\end{equation}\\] We can then substitute this into the initial dictionary to get the dictionary after the first step: \\[\\begin{equation} \\begin{array}{rlrrrr} \\mbox{objective} &amp; = &amp; 3 &amp; + &amp; (-2)w_2 &amp; + &amp; y \\\\ w_1 &amp; = &amp; 1.35 &amp; - &amp; (-1.5) w_2 &amp; - &amp; 4.5y \\\\ x &amp; = &amp; 0.75 &amp; - &amp; 0.5 w_2 &amp; - &amp; 0.5y \\\\ w_3 &amp; = &amp; 0.25 &amp; - &amp; (-0.5) w_2 &amp; - &amp; 0.5y. \\end{array} \\tag{3.2} \\end{equation}\\] Finally, the non-basic variables at the optimal solution are \\(w_1, w_2\\). We can repeat the above process and get the dictionary for the optimal solution: \\[\\begin{equation} \\begin{array}{rlrrrr} \\mbox{objective} &amp; = &amp; 3.3 &amp; + &amp; (-5/3)w_2 &amp; + &amp; (-2/9)w_1 \\\\ y &amp; = &amp; 0.3 &amp; - &amp; (-1/3) w_2 &amp; - &amp; 2/9 w_1 \\\\ x &amp; = &amp; 0.6 &amp; - &amp; 2/3 w_2 &amp; - &amp; (-1/9) w_1 \\\\ w_3 &amp; = &amp; 0.1 &amp; - &amp; (-1/3) w_2 &amp; - &amp; (-1/9) w_1. \\end{array} \\tag{3.3} \\end{equation}\\] Remark. From the dictionary, one can extract the set of basic variables and the set of non-basic variables by looking at the variables appearing on the LHS and RHS, respectively. Furthermore, by setting the non-basic variables to 0, we obtain the very useful fact that the values of the basic variables are simply the constants “\\(b_i\\)”, and the value of the objective function is the constant “\\(c_0\\)”. For example, from the final dictionary above, we can immediately see that \\(x = 0.6\\), \\(y = 0.3\\), \\(w_3 = 0.9\\), and the objective value is \\(3.3%\\) (and \\(w_1 = 0\\) and \\(w_2 = 0.3\\)) at the optimal solution. 3.3 The simplex step We’ll make several simplifying assumptions to begin with and then extend the algorithm to handle more complicated cases. To start, we’ll assume that at each vertex of the feasible region exactly \\(n\\) variables are non-basic. Such a linear program is called non-degenerate. Secondly, for the sake of explaining the algorithm, we’ll assume that out variable names and constants are dynamically updated i.e. after each step we rename the variables so that \\(\\{w_1, \\dots, w_m\\}\\) is the set of basic variables, \\(\\{x_1, \\dots, x_n\\}\\) is the set of non-basic variables and \\(c_j\\), \\(b_i\\), and \\(a_{ij}\\) are the constants appearing in the dictionary so that at the start of each step the dictionary is as follows: \\[\\begin{equation} \\begin{array}{rrrrrrrrrr} \\mbox{objective} &amp; = &amp; c_0 &amp; + &amp; c_1x_1 &amp; + &amp; \\dots &amp; + &amp; c_nx_n \\\\ w_1 &amp; = &amp; b_1 &amp; - &amp; a_{11} x_1 &amp; - &amp; \\dots &amp; - &amp; a_{1n} x_n \\\\ w_2 &amp; = &amp; b_2 &amp; - &amp; a_{21} x_1 &amp; - &amp; \\dots &amp; - &amp; a_{2n} x_n \\\\ &amp; &amp; &amp; &amp; &amp; \\vdots &amp; \\\\ w_m &amp; = &amp; b_m &amp; - &amp; a_{m1} x_1 &amp; - &amp; \\dots &amp; - &amp; a_{mn} x_n \\end{array} \\tag{3.4} \\end{equation}\\] Note that you do not have to make this assumption when actually solving the linear program. This assumption is for exposition purposes only. 3.3.1 Choosing the entering variable We need to choose the entering variable to be one of the non-basic variables. This non-basic variable is going to increase from 0 to a positive value. Because the objective function has the following expression, \\[\\begin{align} \\mbox{objective} = c_0 + c_1x_1 + \\dots + c_nx_n \\end{align}\\] we can choose the variable \\(x_j\\) to be entering if and only if \\(c_j\\) is positive as increasing such a variable increases the objective value. We can think of the entering variable as determining the direction of the simplex step. Example 3.2 In the dictionary (3.1), the objective function is \\(4x + 3y\\). Hence, both \\(x\\) and \\(y\\) can be chosen as the entering variables. Geometrically, we can see that there are two different paths going from the origin to the optimal solution. In the dictionary (3.2), the objective function is \\(3 + (-2)w_2 + y\\). Hence, only \\(y\\) can be the entering variable. In dictionary (3.3), the objective function is \\(3.3 + (-5/3)w_2 + (-2/9)w_1\\). Hence, there cannot be any entering variable. 3.3.2 Choosing the leaving variable Suppose \\(x_j\\) is the chosen entering variable. Instead of choosing the leaving variable directly from among the basic variables, we find the largest value that the variable \\(x_j\\) can be increased to. We can think of finding the leaving variable as determining how far we can move in the direction of the simplex step without leaving the feasible region. As \\(x_j\\) increases \\(w_i\\) will decrease exactly when \\(a_{ij} &gt; 0\\). Because we want all the variables to be non-negative, we must always have \\(w_i = b_i - a_{ij} x_j \\ge 0\\). But this condition must hold true for all such \\(w_i\\). Hence, we get that \\(w_i\\) will be the leaving variable if \\[\\begin{align} i = {\\arg \\min} _{a_{ij} &gt; 0} \\dfrac{b_i}{a_{ij}} \\end{align}\\] In this case, after the simplex step \\(w_i \\to 0\\) and \\(x_j \\to {\\min} _{a_{ij} &gt; 0} \\dfrac{b_i}{a_{ij}}\\). Example 3.3 In the dictionary (3.1), if we choose \\(x\\) to be our entering variable then we need to get the following ratios to compare \\(i\\) \\(a_{ij}\\) \\(b_i\\) \\(b_i/a_{ij}\\) 1 3 3.6 1.2 2 2 1.5 0.75 3 1 1 1 We can see that the smallest ratio is obtained for \\(w_2\\) hence it is the only candidate for the leaving variable. 3.3.3 Tableau Once we have found the entering and leaving variables \\(x_j\\) and \\(w_i\\), we rewrite \\(x_j\\) in terms of \\(w_i\\) and the other non-basic variables to create the updated dictionary as in Example 3.1. This process can get extremely tedious to perform “by hand”. Instead, we introduce tableau to simplify the process. We start by rewriting the constraints in the dictionary with all the variables on the LHS and all the constants on the RHS: \\[\\begin{equation} \\begin{array}{rrrrrrrrrr} a_{11} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{1n} x_n &amp; + &amp; w_1 &amp; &amp; &amp; &amp; &amp; &amp; = &amp; b_1\\\\ a_{21} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{2n} x_n &amp; &amp; &amp; + &amp; w_2 &amp; &amp; &amp; &amp; = &amp; b_2\\\\ &amp; &amp; &amp; &amp; &amp; \\vdots &amp; \\\\ a_{m1} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{mn} x_n &amp; &amp; &amp; &amp; &amp; &amp; + &amp; w_m &amp; = &amp; b_m\\\\ \\end{array} \\tag{3.5} \\end{equation}\\] This can then be encoded using the following augmented matrix: \\[\\begin{equation} \\begin{array}{rrrrrrrrrrr|r} a_{11} &amp; &amp; \\dots &amp; &amp; a_{1n} &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp;b_1\\\\ a_{21} &amp; &amp; \\dots &amp; &amp; a_{2n} &amp; &amp; &amp; 1 &amp; &amp; &amp; &amp;b_2\\\\ &amp; &amp; &amp; &amp; &amp; \\vdots &amp; \\\\ a_{m1} &amp; &amp; \\dots &amp; &amp; a_{mn} &amp; &amp; &amp; &amp; &amp; &amp; 1 &amp;b_m\\\\ \\end{array} \\end{equation}\\] We add back the objective function, but because of a quirk of algebra we need to add the objective function coefficients as follows. \\[\\begin{equation} \\begin{array}{rrrrrrrrrrr|r} c_1 &amp; &amp; \\dots &amp; &amp; c_{n} &amp; 0 &amp; &amp; 0 &amp; \\dots &amp; &amp; 0 &amp;-c_0\\\\ \\hline a_{11} &amp; &amp; \\dots &amp; &amp; a_{1n} &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp;b_1\\\\ a_{21} &amp; &amp; \\dots &amp; &amp; a_{2n} &amp; &amp; &amp; 1 &amp; &amp; &amp; &amp;b_2\\\\ &amp; &amp; &amp; &amp; &amp; \\vdots &amp; \\\\ a_{m1} &amp; &amp; \\dots &amp; &amp; a_{mn} &amp; &amp; &amp; &amp; &amp; &amp; 1 &amp;b_m\\\\ \\end{array} \\end{equation}\\] The columns in this augmented matrix correspond to the variables \\(w_i\\) and \\(x_j\\). The columns with the pivots correspond to the basic variables. If \\(x_j\\) is the entering variable and \\(w_i\\) is the leaving variable, then we simply perform elementary row operations and turn the entry \\(a_{ij}\\) into a pivot for its column. Hence, this step is also called the pivot step. Example 3.4 The tableau corresponding to the dictionary (3.1) is as follows: \\[\\begin{align} \\begin{bmatrix} 4 &amp; 3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 3 &amp; 6 &amp; 1 &amp; 0 &amp; 0 &amp; 3.6 \\\\ \\boxed{2} &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1.5 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\end{bmatrix} \\end{align}\\] If we choose \\(x\\) as the entering variable and \\(w_2\\) as the leaving variable then we need to pivot about the entry \\(a_{21}\\) using elementary row operations to get the following tableau: \\[\\begin{align} \\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; -2 &amp; 0 &amp; -3 \\\\ 0 &amp; 4.5 &amp; 1 &amp; -1.5 &amp; 0 &amp; 1.35 \\\\ \\boxed{1} &amp; 0.5 &amp; 0 &amp; 0.5 &amp; 0 &amp; 0.75 \\\\ 0 &amp; 0.5 &amp; 0 &amp; -0.5 &amp; 1 &amp; 0.25 \\end{bmatrix} \\end{align}\\] which corresponds to the dictionary (3.2). 3.4 Stopping conditions Once we’ve found the entering and leaving variables, we can update the dictionary using the pivot step and start the process again. However, we might not always be able to find the entering and leaving variables. 3.4.1 No entering variable If no entering variable is found, then the geometry tells us that there is no direction in which the objective value can be increased i.e. we’re at a local maxima. But because the objective function is a linear function this local maxima is also an absolute maxima and provides an optimal solution to our linear program. Algebraically, this happens when none of the \\(c_i\\) are positive. 3.4.2 No leaving variable If no leaving variable is found, then the geometry tells us that we can keep increasing the entering variable indefinitely without leaving the feasible region. Such a linear program is called unbounded. An unbounded linear program has no optimal solution as the objective value can be made arbitrary large without leaving the feasible region. Algebraically, this happens when none of the \\(a_{ij}\\) are positive. "],["initialization.html", "Chapter 4 Initialization 4.1 Auxiliary linear program 4.2 Combined tableau", " Chapter 4 Initialization The simplex method starts at a vertex and tries to find an adjacent vertex with a higher objective value. We can start this process at the origin if it is a vertex of the feasible region. However, this is not always the case. The origin is in the feasible region of the standard linear program (2.1) if and only if \\(b_i \\ge 0\\) for all \\(1 \\le i \\le m.\\) When the origin is not a vertex of the feasible region, we need a process to find some vertex of the feasible region. This is called the initialization phase or Phase I of the simplex algorithm. 4.1 Auxiliary linear program We say that a linear program is feasible if its feasible region is non-empty. The initialization phase determines if a standard linear program is feasible and if it is then finds a vertex of the feasible region. To do this we create an auxiliary linear program whose optimal solution provides a feasible solution of the original linear program. The auxiliary linear program of the standard linear program (2.1) is defined as follows: \\[\\begin{equation} \\begin{array}{lrrrrrrrrrrr} \\mbox{maximize: } &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; - &amp; x_0 &amp; \\\\ \\mbox{subject to: } &amp; &amp; &amp; a_{11} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{1n} x_n &amp; - &amp;x_0 &amp; \\leq &amp; b_1 \\\\ &amp; &amp; &amp; a_{21} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{2n} x_n &amp; - &amp;x_0 &amp; \\leq &amp; b_2 \\\\ &amp; &amp; &amp; &amp; &amp; \\vdots &amp; \\\\ &amp; &amp; &amp; a_{m1} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{mn} x_n &amp; - &amp;x_0 &amp; \\leq &amp; b_m \\\\ &amp; &amp; &amp; x_1, &amp; x_2, &amp; \\dots &amp;, &amp; x_n &amp; , &amp; x_0 &amp; \\geq &amp; 0 \\end{array} \\tag{4.1} \\end{equation}\\] One can show, using the extreme value theorem, that the auxiliary linear program (4.1) always has an optimal solution. Furthermore, using some basic algebraic manipulations one can prove the following theorem. Theorem 4.1 Suppose \\((k_1, k_2, \\dots, k_n, k_0)\\) is an optimal solution of the auxiliary linear program (4.1). Then, the standard linear program (2.1) is feasible if and only if \\(k_0 = 0\\). In this case, \\((k_1, k_2, \\dots, k_n)\\) is a vertex of the feasible region of (2.1). To understand the auxiliary linear program, it is better to write it in the following non-standard form: \\[\\begin{equation} \\begin{array}{lrrrrrrrrrrr} \\mbox{minimize: } &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; x_0 &amp; \\\\ \\mbox{subject to: } &amp; &amp; &amp; a_{11} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{1n} x_n &amp; \\leq &amp; b_1 &amp; + &amp; x_0 \\\\ &amp; &amp; &amp; a_{21} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{2n} x_n &amp; \\leq &amp; b_2 &amp; + &amp; x_0 \\\\ &amp; &amp; &amp; &amp; &amp; \\vdots &amp; \\\\ &amp; &amp; &amp; a_{m1} x_1 &amp; + &amp; \\dots &amp; + &amp; a_{mn} x_n &amp; \\leq &amp; b_m &amp; + &amp; x_0 \\\\ &amp; &amp; &amp; x_1, &amp; x_2, &amp; \\dots &amp;, &amp; x_n &amp; , &amp; x_0 &amp; \\geq &amp; 0 \\end{array} \\end{equation}\\] We can then interpret \\(x_0\\) as a relaxation of the constraints. The auxiliary linear program is then asking - what is the smallest constraint relaxation necessary to make our linear program feasible?. The primary linear program is feasible if and only if no relaxation is necessary. If the origin is not a vertex of the feasible region, then the method of solving the standard linear program (2.1), starting with Phase I, is as follows: Form the auxiliary linear program and its tableau. Note that we still cannot proceed normally as even for the auxiliary linear program the \\(b_i\\)’s are not all non-negative. Perform a pivot operation about the entry in the column corresponding to the variable \\(x_0\\) and the row corresponding to the most negative \\(b_i\\). This results in a dictionary where all the \\(b_i\\)’s are now non-negative. Solve the auxiliary linear program using the simplex method. Suppose \\((k_1, k_2, \\dots, k_n, k_0)\\) is an optimal solution of the auxiliary linear program. If \\(k_0 \\neq 0\\), then we halt as the primary linear program is not feasible. If \\(k_0 = 0\\), then we proceed to Phase II with the initial vertex \\((k_1, \\dots, k_n)\\). Find the dictionary at the initial vertex and proceed with the simplex method to find an optimal solution. 4.2 Combined tableau There is a shortcut to combining both Phase I and Phase II and reduce the number of pivots necessary. We create a combined tableau which contains information about both the auxiliary linear program and the primary linear program as follows: \\[\\begin{equation} \\begin{array}{rrrrrrrrrrrr|l} c_1 &amp; &amp; \\dots &amp; &amp; c_{n} &amp; 0 &amp; &amp; 0 &amp; \\dots &amp; &amp; 0 &amp; 0 &amp; 0\\\\ \\hline 0 &amp; &amp; \\dots &amp; &amp; 0 &amp; 0 &amp; &amp; 0 &amp; \\dots &amp; &amp; 0 &amp; -1 &amp; 0\\\\ \\hline a_{11} &amp; &amp; \\dots &amp; &amp; a_{1n} &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; -1 &amp;b_1\\\\ a_{21} &amp; &amp; \\dots &amp; &amp; a_{2n} &amp; &amp; &amp; 1 &amp; &amp; &amp; &amp; -1 &amp;b_2\\\\ &amp; &amp; &amp; &amp; &amp; \\vdots &amp; &amp; &amp; &amp; &amp; &amp; \\vdots &amp; \\vdots \\\\ a_{m1} &amp; &amp; \\dots &amp; &amp; a_{mn} &amp; &amp; &amp; &amp; &amp; &amp; 1 &amp; -1 &amp;b_m\\\\ \\end{array} \\end{equation}\\] The first row of the tableau is the objective function of the primary linear program and the second row of the tableau is the objective of the auxiliary linear program. We use the combined tableau to first perform Phase I and then neglect the auxiliary objective and the variable \\(x_0\\) and proceed on to Phase II using the same tableau. Example 4.1 Consider the following linear program: \\[\\begin{equation} \\begin{array}{rrrrrl} \\mbox{maximize:} &amp; x &amp; + &amp; y \\\\ \\mbox{subject to:} &amp; x &amp; + &amp; 2y &amp; \\le &amp; 6 \\\\ &amp; -x &amp; &amp; &amp; \\le &amp; -1 \\\\ &amp; &amp; &amp; -y &amp; \\le &amp; -2 \\\\ &amp; x &amp; , &amp; y &amp; \\ge &amp; 0. \\end{array} \\end{equation}\\] It is easy to see that feasible region is given by the triangle with vertices \\((1,2)\\), \\((2,2)\\), and \\((1, 2.5)\\) and the optimal solution is given by \\((2,2)\\). Because \\((0,0)\\) is not feasible, we need the two-phase simplex method to solve this problem. We start with the combined tableau: \\[\\begin{align} \\begin{bmatrix} 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; -1 &amp; 0 \\\\ 1 &amp; 2 &amp; 1 &amp; 0 &amp; 0 &amp; -1 &amp; 6 \\\\ -1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1 &amp; -1 \\\\ 0 &amp; -1 &amp; 0 &amp; 0 &amp; 1 &amp; \\boxed{-1} &amp; -2 \\end{bmatrix} \\end{align}\\] The first pivot is in the column corresponding to the variable \\(x_0\\) and the row corresponding to the most negative \\(b_i\\) (which is the last row). This results in the following combined tableau: \\[\\begin{align} \\begin{bmatrix} 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; -1 &amp; 0 &amp; 2 \\\\ 1 &amp; 3 &amp; 1 &amp; 0 &amp; -1 &amp; 0 &amp; 8 \\\\ -1 &amp; 1 &amp; 0 &amp; 1 &amp; -1 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; -1 &amp; 1 &amp; 2 \\end{bmatrix} \\end{align}\\] We then continue with the standard simplex method to find the solution: \\[\\begin{align} \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; -2 &amp; -3 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; -1 &amp; \\boxed{0} \\\\ 0 &amp; 0 &amp; 1 &amp; 1 &amp; 2 &amp; -4 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; -1 &amp; 1 &amp; 2 \\\\ 1 &amp; 0 &amp; 0 &amp; -1 &amp; 0 &amp; 1 &amp; 1 \\end{bmatrix} \\end{align}\\] We see that the optimal value is 0 and hence the primary linear program is feasible. We then remove the auxiliary objective and coefficient to get the following tableau for the primary linear program: \\[\\begin{align} \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; -3 \\\\ 0 &amp; 0 &amp; 1 &amp; \\boxed{1} &amp; 2 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; -1 &amp; 2 \\\\ 1 &amp; 0 &amp; 0 &amp; -1 &amp; 0 &amp; 1 \\end{bmatrix} \\end{align}\\] We continue solving this using the simplex method to get the final tableau \\[\\begin{align} \\begin{bmatrix} 0 &amp; 0 &amp; -1 &amp; 0 &amp; -1 &amp; -4 \\\\ 0 &amp; 0 &amp; 1 &amp; 1 &amp; 2 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; -1 &amp; 2 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 &amp; 2 &amp; 2 \\end{bmatrix} \\end{align}\\] The final non-basic variables are \\(w_1\\) and \\(w_3\\) and the basic variables are \\(x, y, w_2\\) with values \\(2, 2, 1\\), respectively. The optimal objective value is \\(4\\). "],["halting-problem.html", "Chapter 5 Halting problem 5.1 Fundamental theorem of linear programming 5.2 Degeneracy 5.3 Bland’s rule", " Chapter 5 Halting problem We now have a complete algorithm for solving a standard linear program. However, we have not shown that it always finds the optimal solution. Let us start with the existence of optimal solution. 5.1 Fundamental theorem of linear programming To resolve the issue of getting stuck in a loop, we first need the following theorem about linear programs: Theorem 5.1 (Fundamental theorem of linear programming) Every standard linear program is exactly one of the following: Infeasible, Unbounded, Has an optimal solution. In this case, the optimal solution is obtained at one of the vertices of the feasible region. This theorem is an easy corollary of the extreme value theorem for multi-variate functions and relies on the closedness of the feasible region of a standard linear program and the continuity of the objective function. We see that the simplex method is able to detect all three cases. The first case happens when the Phase I algorithm is unable to find a feasible solution, the second case happens when no leaving variable is found, and the third case happens when no entering variable is found. However, it is possible for the simplex method to get stuck in a loop. This is called cycling. One way to show that the simplex method does not cycle is to show that the objective value always increases after the simplex step. If this were the case then we would never visit the same vertex twice. The vertices of the feasible region are obtained by intersecting constraint boundaries and hence only are finite in number (even if the region is unbounded). So, if we never visit the same vertex twice, the simplex method must halt. However, it is not always the case that the objective value increases after a simplex step! 5.2 Degeneracy We saw in Section 3.3.2 that after the simplex step the entering and leaving variable gets updated as follows: \\[\\begin{align} x_j &amp; \\mapsto b_i/a_{ij} \\\\ w_i &amp; \\mapsto 0. \\end{align}\\] This increases the value of the objective function by \\(c_j b_i/a_{ij}\\). Because of the criterion for choosing the entering and leaving variables, the constants \\(c_i\\) and \\(a_{ij}\\) are always positive. We know that \\(b_i\\) this is the value of the basic variable \\(w_i\\) and hence must be \\(\\ge 0\\). But we cannot guarantee that \\(b_i &gt; 0\\). If \\(b_i = 0\\), then the objective value does not increase after the simplex step. This can result in the simplex method to get stuck in a loop. We say that the dictionary at a feasible vertex is degenerate if some \\(b_i = 0\\). In this case, one of the basic variables also has the value 0 at this vertex. Geometrically, this is saying that more than \\(n\\) constraints are satisfied at this vertex. Example 5.1 The following slight modification of Example (1.2) is a degenerate linear program: \\[\\begin{equation} \\begin{array}{rrrrrl} \\mbox{maximize:} &amp; 4x &amp; + &amp; 3y \\\\ \\mbox{subject to:} &amp; 3x &amp; + &amp; 6y &amp; \\le &amp; 4.5 \\\\ &amp; 2x &amp; + &amp; y &amp; \\le &amp; 1.5 \\\\ &amp; x &amp; + &amp; y &amp; \\le &amp; 1 \\\\ &amp; x &amp; , &amp; y &amp; \\ge &amp; 0. \\end{array} \\end{equation}\\] At the optimal solution, \\((0.5, 0.5)\\) all three constraints are met. At this vertex, one of the rows is \\[\\begin{align} w_3 &amp;= 0 + 0.33 w_2 + 0.11 w_1. \\end{align}\\] Example 5.2 Consider the following degenerate linear program: \\[\\begin{equation} \\begin{array}{rrrrrrrl} \\mbox{maximize:} &amp; x_1 &amp; - &amp; 2x_2 &amp; &amp; &amp; - &amp; 2x_4 \\\\ \\mbox{subject to:} &amp; 0.5 x_1 &amp; - &amp; 3.5x_2 &amp; - &amp; 2x_3 &amp; + &amp; 4 x_4 &amp; \\le &amp; 0 \\\\ &amp; 0.5 x_1 &amp; - &amp; x_2 &amp; - &amp; 0.5 x_3 &amp; + &amp; 0.5 x_4 &amp; \\le &amp; 0 \\\\ &amp; x_1 &amp; &amp; &amp; &amp; &amp; &amp; &amp; \\le &amp; 1 \\\\ &amp; x_1 &amp; , &amp; x_2 &amp; , &amp; x_3 &amp; , &amp; x_4 &amp; \\ge &amp; 0 \\\\ \\end{array} \\end{equation}\\] The following is a valid sequence of simplex steps: \\(x_1\\) enters and \\(w_1\\) leaves, \\(x_2\\) enters and \\(w_2\\) leaves, \\(x_3\\) enters and \\(x_1\\) leaves, \\(x_4\\) enters and \\(x_2\\) leaves, \\(w_1\\) enters and \\(x_3\\) leaves, \\(w_2\\) enters and \\(x_4\\) leaves. At the end of the \\(6^{th}\\) simplex step, we end up looping back to the origin. 5.3 Bland’s rule There are various ways of dealing with cycling. The simplex way is to remember all the simplex steps taken so far and if we happen to revisit a vertex then we simple make a different choice of entering and leaving variables. However, as it turns out, there is a much simpler way to avoid cycling by using Bland’s rule. Bland’s rule says that if there are multiple candidates for the entering/variable then we choose the one with the smallest index. (We assume that the decision variables have a smaller index than the slack variables.) Theorem 5.2 (Bland's rule) The simplex method always terminates provided that both the entering and the leaving variable are chosen according to Bland’s rule. The proof of this theorem is too complicated for this course. With this modification, for both Phase I and Phase II of the simplex method, we now have a complete algorithm for solving linear programs. Example 5.3 In Example 5.2, the sixth simplex step violates Bland’s rule. Once we choose the entering and leaving variables using Bland’s rule, we can check that the simplex step for Example 5.2 indeed terminates at the optimal solution. "],["standardization.html", "Chapter 6 Standardization", " Chapter 6 Standardization A general linear program is an optimization question where the objective function is a linear program and the constraints are linear equalities or inequalities. Remark. We do not allow the inequalities to be “&lt;” or “&gt;”. This is because the region defined by using such inequalities is an open set and extreme value theorem is not applicable to these open sets. This further implies that the fundamental theorem of linear programming is no longer valid for these kinds of constraints. For example, consider the following linear program: \\[\\begin{align} \\mbox{maximize: } &amp; x \\\\ \\mbox{subject to: } &amp; x &lt; 1 \\\\ &amp; x \\geq 1. \\\\ \\end{align}\\] The feasible region is \\([0, 1)\\) which is bounded from above and yet there is no optimal solution. Given a general linear program, we can standardize it by a sequence of algebraic transformations and convert it to a standard linear program of the form (2.1). 6.0.1 Objective If the goal is to minimize the objective function then to convert it to a maximization problem, we simply multiply the objective function by \\(-1\\). Minimizing a function \\(f\\) is the same as maximizing \\(-f\\). 6.0.2 Constraints We first move all the variables in the constraints to the LHS and the constants to the RHS and then fix the constraints one at a time. If a constraint has the inequality \\(\\geq\\) then we multiply both sides of the constraint by -1 to change the inequality to \\(\\leq\\). If a constraint is an equality constraint, then we replace the equality with two constraints: one with the inequality \\(\\leq\\) and one with the inequality \\(\\geq\\). 6.0.3 Variables If a variable has a non-positivity constraint of the form \\(x_j \\le 0\\), then we replace \\(x_j\\) with \\(-x_j\\) everywhere. If a variable \\(x_j\\) is free i.e. it does not have any sign constraints on it, then we introduce two new variables \\(x_j&#39;\\), \\(x_j&#39;&#39;\\) which are both non-negative and make the substitution \\(x_j = x_j&#39; - x_j&#39;&#39;\\). This trick works because any real number can be written as a difference of two non-negative reals. "],["dual-linear-program.html", "Chapter 7 Dual linear program", " Chapter 7 Dual linear program In the next few chapters we’ll prove duality theorems about linear programs. We start by introducing the matrix notation. We’ll let \\(x\\) denote the vector of decision variables, \\(b\\) the vector of upper bounds, \\(c\\) the vector of objective coefficients, and \\(A\\) the matrix of constraints in the standard linear program (2.1). \\[\\begin{align} x = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix}, \\quad b = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{bmatrix}, \\quad c = \\begin{bmatrix} c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_n \\end{bmatrix}, \\quad A = \\begin{bmatrix} a_{11} &amp; a_{12} &amp; \\dots &amp; a_{1n} \\\\ a_{21} &amp; a_{22} &amp; \\dots &amp; a_{2n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{m1} &amp; a_{m2} &amp; \\dots &amp; a_{mn} \\end{bmatrix}. \\end{align}\\] We’ll assume that \\(c_0 = 0\\) at the start. The standard linear program (2.1) can be written as follows: \\[\\begin{equation} \\begin{array}{lrll} \\mbox{maximize: } &amp; c^T x \\\\ \\mbox{subject to: } &amp; A x &amp; \\leq &amp; b \\\\ &amp; x &amp; \\geq &amp; 0. \\end{array} \\end{equation}\\] The dual of this linear program is defined as the following linear program: \\[\\begin{equation} \\begin{array}{lrll} \\mbox{minimize: } &amp; b^T y \\\\ \\mbox{subject to: } &amp; A^T y &amp; \\geq &amp; c \\\\ &amp; y &amp; \\geq &amp; 0, \\end{array} \\tag{7.1} \\end{equation}\\] where \\(y = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_m \\end{bmatrix}\\) is the vector of dual decision variables. The original linear program is called the primal. The dual decision variables correspond to the constraints of the original linear program. By explicitly computation, we can easily prove that the following theorem. Theorem 7.1 The (standardization of) the dual of the (standardized) dual is the primal. Hence, we think of linear programs as coming in primal-dual pairs. Every linear program has a dual and it is itself the dual of the dual. The dual decision variables correspond to the constraints of the original linear program and the primal decision variables correspond to the constraints of the dual. Example 7.1 The dual of (1.2) is: \\[\\begin{equation} \\begin{array}{lrrrrrrrrrr} \\mbox{minimize: } &amp; 3.6 y_1 &amp; + &amp; 1.5 y_2 &amp; + &amp; y_3 \\\\ \\mbox{subject to: } &amp; 3y_1 &amp; + &amp; 2 y_2 &amp; + &amp; y_3 &amp; \\geq &amp; 4 \\\\ &amp; 6y_1 &amp; + &amp; y_2 &amp; + &amp; y_3 &amp; \\geq &amp; 3 \\\\ &amp; y_1 &amp; , &amp; y_2 &amp; , &amp; y_3 &amp; \\geq &amp; 0. \\end{array} \\tag{7.2} \\end{equation}\\] The variable \\(y_1\\) corresponds to the “maturity”, the variable \\(y_2\\) corresponds to the “risk”, and the variable \\(y_3\\) corresponds to the “percentage”. We can think of these variables as “internal costs/prices”. The expression \\(3y_1 + 2 y_2 + y_3\\) is the “price” of the corporate bond and the expression \\(6 y_1 + y_2 + y_3\\) is the “price” of the government bond. The dual constraints are saying that the “internal price” of either of the two bonds should be at least as large as the “external price” i.e. yield of the corporate bond. "],["weak-and-strong-duality.html", "Chapter 8 Weak and strong duality 8.1 Weak duality 8.2 Strong duality", " Chapter 8 Weak and strong duality Consider the standard linear program (primal) (2.1) and its dual (7.1). We say that a vector \\(x = \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix}\\) is primal feasible if it is in the feasible region of the primal and a vector \\(y = \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_m \\end{bmatrix}\\) is dual feasible if it is in the feasible region of the dual. 8.1 Weak duality Theorem 8.1 (Weak duality) Suppose \\(x\\) is primal feasible and \\(y\\) is dual feasible. Then the primal objective value at \\(x\\) is less than or equal to the dual objective value at \\(y\\). Proof. The proof relies on analyzing the term \\(y^T A x\\) and follows by looking at the following sequence of inequalities: \\[\\begin{align} b^T y &amp; = y^T b \\\\ &amp; \\ge y^T (Ax) &amp;&amp; \\mbox{ as } Ax \\leq b \\mbox{ and } y \\geq 0 \\\\ &amp; = (y^T A x)^T \\\\ &amp; = x^T A^T y \\\\ &amp; \\ge x^T c &amp;&amp; \\mbox{ as } A^Ty \\geq c \\mbox{ and } x \\geq 0 \\\\ &amp; = c^T x. \\end{align}\\] We get several immediate corollaries out of Weak duality. Corollary 8.1 If the primal is unbounded, then the dual is infeasible. Corollary 8.2 If the dual is unbounded, then the primal is infeasible. Corollary 8.3 If both the primal and dual have optimal solutions, then the optimal value of the primal is less than or equal to the optimal value of the dual. We cannot say anything about the dual in the case when the primal is infeasible. Similarly, we cannot conclude anything about the existence of an optimal value of the dual in the case when the primal has an optimal solution. Some variant of weak duality usually exists for optimization problems which are non-linear. However, the strong duality theorem stated below is more uncommon and only holds true under very special conditions on the constraints. 8.2 Strong duality The tableau of the primal problem (2.1) is as follows: \\[\\begin{equation} \\begin{array}{ll|r} c^T &amp; 0 &amp; c_0 \\\\ \\hline A &amp; I_m &amp; b \\end{array} \\tag{8.1} \\end{equation}\\] We can standardize the dual problem (7.1) and form its tableau: \\[\\begin{equation} \\begin{array}{ll|r} -b^T &amp; 0 &amp; -c_0 \\\\ \\hline -A^T &amp; I_n &amp; -c \\end{array} \\tag{8.2} \\end{equation}\\] We will such tableaus duals of each other. More generally, we’ll say that two tableaus (of appropriate dimensions) are duals of each other if after rearranging the pivot columns, if necessary, they’re of the above form. One can show the following theorem by explicit computation: Lemma 8.1 Consider the two dual tableaus (8.1) and (8.2) . If we pivot the first tableau about the \\(i^{th}\\) row and \\(j^{th}\\) column of \\(A\\) and the second tableau about the \\(i^{th}\\) column and \\(j^{th}\\) row of \\(-A^T\\), then the resulting tableaus remain duals of each other. Lemma 8.2 If the tableau (8.1) corresponds to an optimal solution of the primal then the tableau (8.2) corresponds to an optimal solution of the dual. Proof. The tableau (8.1) corresponds to an optimal solution of the primal precisely when (primal optimality) \\(c^T \\le 0\\) as in this case no entering variable can be found for the primal, and (primal feasibility) \\(b \\ge 0\\). These conditions translate to (dual optimality) \\(-b^T \\le 0\\) as in this case no entering variable can be found for the dual, and (dual feasibility) \\(-c \\ge 0\\). Using the above two lemmas, and by explicitly running the simplex method we get the following result: Theorem 8.2 (Strong duality) If the primal has an optimal solution then so does the dual. Moreover, they have the same optimal values. Proof. At the optimal solution for the primal, we have a set of basic and non-basic variables. We can perform a sequence of pivot operations to get this tableau from the initial tableau. We then perform the corresponding pivots on the dual tableau. By Lemma 8.1 the resulting tableau will be dual to the primal tableau at the optimal solution. By Lemma 8.2 the dual is also optimal and has the same objective value. "],["certificate-of-optimality.html", "Chapter 9 Certificate of optimality 9.1 Complimentary slackness", " Chapter 9 Certificate of optimality We can use the two duality theorems to come up with a fast way to check optimality. Theorem 9.1 (Certificate of optimality) \\(x\\) is an optimal solution for the primal and \\(y\\) is an optimal solution for the dual if and only if \\(x\\) is primal-feasible, \\(y\\) is dual-feasible, \\(c^T x = b^T y\\) i.e. the primal objective value at \\(x\\) is equal to the dual objective value at \\(y\\). Proof. ( \\(\\Rightarrow\\) ) If \\(x\\) and \\(y\\) are optimal solutions, then they are feasible by definition and by strong duality (Theorem 8.2) they have the same objective value. ( \\(\\Leftarrow\\) ) If \\(x\\) and \\(y\\) are feasible solutions then by weak duality (Theorem 8.1) the dual objective values provide an upper bound on the primal objective value. Because this upper bound is attained at \\(x\\), \\(x\\) must be an optimal solution of the primal. Similarly, for \\(y\\). 9.1 Complimentary slackness There is another closely related method for verifying the correctness of solution using primal and dual slack variables. Denote by \\(w = \\begin{bmatrix} w_1 \\\\ \\vdots \\\\ w_m \\end{bmatrix}\\) the primal slack variables and by \\(z = \\begin{bmatrix} v_1 \\\\ \\vdots \\\\ v_n \\end{bmatrix}\\) the dual slack variables. More explicitly, \\[\\begin{align} w &amp;= b - A x \\\\ z &amp;= -c + A^T y. \\end{align}\\] We use this convention for \\(z\\) as then at a dual feasible solution \\(z \\ge 0\\). Theorem 9.2 (Complementary slackness) Suppose \\(x\\) is primal feasible and \\(y\\) is dual feasible. Then \\(x\\) and \\(y\\) are optimal if and only if for all \\(1 \\le j \\le n\\), \\(x_j z_j = 0\\), and for all \\(1 \\le i \\le m\\), \\(y_i w_i = 0\\). Proof. The proof is in two steps. We first show a weaker statement about the vanishing of two scalars and then show that the vanishing of these scalars implies complementary slackness. Claim: \\(x\\) and \\(y\\) are optimal solutions if and only if \\(x^T z = 0\\) and \\(y^T w = 0\\). We start by rewriting the slack variable: \\[\\begin{align} &amp;&amp; x^T z = 0 &amp;&amp; \\mbox{ and } &amp;&amp; y^T w = 0 \\\\ \\Leftrightarrow &amp;&amp; x^T (-c + A^T y) = 0 &amp;&amp; \\mbox{ and } &amp;&amp; y^T (b - A x) = 0 \\\\ \\Leftrightarrow &amp;&amp; x^T c = x^T A^T y &amp;&amp; \\mbox{ and } &amp;&amp; y^T b = y^T A x \\\\ \\Leftrightarrow &amp;&amp; c^T x = y^T A x &amp;&amp; \\mbox{ and } &amp;&amp; b^T y = y^T A x \\\\ \\end{align}\\] Thus we are reduced to showing that \\(x\\) and \\(y\\) are optimal solutions if and only if \\(c^T x = y^T A x\\) and \\(b^T y = y^T A x\\). ( \\(\\Leftarrow\\) ) As \\(c^T x = y^T A x = b^T y\\), and \\(x\\) and \\(y\\) are given to be feasible, \\(x\\) and \\(y\\) are optimal by Theorem 9.1. ( \\(\\Rightarrow\\) ) By the proof of weak duality 8.1, we know that as \\(x\\) and \\(y\\) are feasible, \\[c^T x \\le y^T A x \\le b^T y.\\] By strong duality, as \\(x\\) and \\(y\\) are optimal \\[c^T x = b^T y.\\] The only way the two can be simultaneously true is if \\(c^T x = y^T A x\\) and \\(b^T y = y^T A x\\). Claim: \\(x^T z = 0\\) and \\(y^T w = 0\\) if and only if for all \\(1 \\le j \\le n\\), \\(x_j z_j = 0\\), and for all \\(1 \\le i \\le m\\), \\(y_i w_i = 0\\). This follows from the fact that at a feasible solution \\(x, y, w, z \\ge 0\\). "],["dual-of-a-general-linear-program.html", "Chapter 10 Dual of a general linear program", " Chapter 10 Dual of a general linear program We saw how to standardized non-standard linear programs in Chapter 6. We need to “fix” the objective function, constraints, and signs of decision variables. To find the dual of a non-standard linear program, we can first standardize it and then form the dual. However, doing so changes the coefficients of the constraints. After standardization, we can “revert the standardization” of the dual so that the matrix that defines the dual constraints is precisely the transpose of the matrix that defines the primal constraints. This requires us to change appropriate inequalities in the dual as described in the following table. Primal Dual \\(a_{i1} x_1 + \\dots + a_{in} x_n \\le b_i\\) \\(y_i \\ge 0\\) \\(a_{i1} x_1 + \\dots + a_{in} x_n \\ge b_i\\) \\(y_i \\le 0\\) \\(a_{i1} x_1 + \\dots + a_{in} x_n = b_i\\) \\(y_i\\) is free \\(x_j \\ge 0\\) \\(a_{1j}y_1 + \\dots + a_{mj} y_m \\ge c_j\\) \\(x_j \\le 0\\) \\(a_{1j}y_1 + \\dots + a_{mj} y_m \\le c_j\\) \\(x_j\\) is free \\(a_{1j}y_1 + \\dots + a_{mj} y_m = c_j\\) Note that if we define slack variables as before \\[\\begin{align} w &amp;= b - A x \\\\ z &amp;= -c + A^T y, \\end{align}\\] then even for a general linear program we will have \\(x_j w_j \\ge 0\\) for all \\(1 \\le j \\le n\\) and \\(y_i z_i \\ge 0\\) for all \\(1 \\le i \\le m\\). Hence, complementary slackness, as stated in Theorem 9.2, holds true for the general linear programs. "],["sensitivity-analysis---constraints.html", "Chapter 11 Sensitivity analysis - Constraints 11.1 Matrix notation 11.2 Range of optimality 11.3 Rate of change 11.4 Dual variables", " Chapter 11 Sensitivity analysis - Constraints Linear programs are used to model real world problems. Such models are at best approximate and at worst inaccurate. As such, it is important to understand the sensitivity of our solution to changes in the model. This is broadly called sensitivity analysis. We will focus on understanding the dependence of the optimal objective value of the standard linear program (2.1) on the constants \\(b_i\\) and \\(c_j\\). Throughout this chapter, we’ll assume that our linear programs have an optimal solution. 11.1 Matrix notation In our previous analysis of the simplex method, we assumed that the constants \\(b_i\\), \\(c_j\\), and \\(a_{ij}\\) were being dynamically updated. However, now we’ll assume that they are fixed constants as our goal is no longer to run the simplex algorithm but rather to find the dependence of the solution on the initial values of these constants. We will start by finding a succinct way to describe the dictionary at the optimal solution. Recall that the decision and slack variables are related to each other by the Equation (3.5) which can be written as: \\[\\begin{equation} \\begin{bmatrix} A &amp; I_m \\end{bmatrix} \\begin{bmatrix} x \\\\ w \\end{bmatrix} = b. \\tag{11.1} \\end{equation}\\] Let \\(\\widehat{A} := \\begin{bmatrix} A &amp; I_m \\end{bmatrix}\\). We’ll decompose \\(\\widehat{A}\\) using the basic and non-basic variables. Then let \\(\\mathcal{B}\\) be the matrix formed by combining the columns of \\(\\widehat{A}\\) corresponding to the basic variables and let \\(\\mathcal{N}\\) be the matrix formed by combining the columns of \\(\\widehat{A}\\) corresponding to the non-basic variables. Let \\(x_{\\mathcal{B}}\\) be the vector of basic variables and \\(x_{\\mathcal{N}}\\) be the vector of non-basic variables. By rearranging the columns of \\(\\widehat{A}\\) if necessary, we can rewrite (11.1) as \\[\\begin{align} &amp;&amp; \\begin{bmatrix} \\mathcal{B} &amp; \\mathcal{N} \\end{bmatrix} \\begin{bmatrix} x_{\\mathcal{B}} \\\\ x_{\\mathcal{N}} \\end{bmatrix} &amp;= b,\\\\ \\implies &amp;&amp; \\mathcal{B} x_{\\mathcal{B}} + \\mathcal{N} x_{\\mathcal{N}} &amp;= b, \\\\ \\implies &amp;&amp; \\mathcal{B} x_{\\mathcal{B}} &amp;= b - \\mathcal{N} x_{\\mathcal{N}}. \\end{align}\\] One can show that the matrix \\(\\mathcal{B}\\) is always invertible (hence the name “basic” variables) and the above equation can be further simplified to the following: \\[\\begin{equation} x_{\\mathcal{B}} = \\mathcal{B}^{-1} b - \\mathcal{B}^{-1} \\mathcal{N} x_{\\mathcal{N}}. \\tag{11.2} \\end{equation}\\] This is nothing but the dictionary at the optimal solution. Example 11.1 Consider Example (1.2) again. At the optimal solution \\(w_1\\) and \\(w_2\\) are non-basic and have the value 0, and \\(x\\), \\(y\\), and \\(w_3\\) are basic with values \\(0.3\\), \\(0.6\\), and \\(0.9\\), respectively. Using the above notation, we have \\[\\begin{align} \\mathcal{B} = \\begin{bmatrix} 3 &amp; 6 &amp; 0 \\\\ 2 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 \\end{bmatrix}, x_{\\mathcal{B}} = \\begin{bmatrix} x \\\\ y \\\\ w_3 \\end{bmatrix}, \\\\ \\mathcal{N} = \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\\\ 0 &amp; 0 \\end{bmatrix}, x_{\\mathcal{N}} = \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix}. \\end{align}\\] Using Equation (11.2) the dictionary at the optimal solution becomes \\[\\begin{align} \\begin{bmatrix} x \\\\ y \\\\ w_3 \\end{bmatrix} &amp;= \\begin{bmatrix} 3 &amp; 6 &amp; 0 \\\\ 2 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 \\end{bmatrix}^{-1} \\begin{bmatrix} 3.6 \\\\ 1.5 \\\\ 1 \\end{bmatrix} - \\begin{bmatrix} 3 &amp; 6 &amp; 0 \\\\ 2 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 \\end{bmatrix}^{-1} \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\\\ 0 &amp; 0 \\end{bmatrix} \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix} \\\\ &amp; = \\begin{bmatrix} -1/9 &amp; 2/3 &amp; 0 \\\\ 2/9 &amp; -1/3 &amp; 0 \\\\ -1/9 &amp; -1/3 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 3.6 \\\\ 1.5 \\\\ 1 \\end{bmatrix} - \\begin{bmatrix} -1/9 &amp; 2/3 &amp; 0 \\\\ 2/9 &amp; -1/3 &amp; 0 \\\\ -1/9 &amp; -1/3 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\\\ 0 &amp; 0 \\end{bmatrix} \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix} \\\\ &amp; = \\begin{bmatrix} 0.6 \\\\ 0.3 \\\\ 0.9 \\end{bmatrix} - \\begin{bmatrix} -1/9 &amp; 2/3 \\\\ 2/9 &amp; -1/3 \\\\ -1/9 &amp; -1/3 \\end{bmatrix} \\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix}. \\end{align}\\] This is precisely the dictionary (3.3) at the optimal solution. Because we set the non-basic variables \\(x_{\\mathcal{N}}\\) to 0 at any vertex, and in particular, at the the optimal solution, using the Equation (11.2) we get the following useful result: Lemma 11.1 Using the above notation, \\(\\mathcal{B}^{-1}b\\) is the value of the basic variables at the optimal solution. 11.2 Range of optimality We now try to determine the change in optimal solution as we change the constraint upper bounds \\(b_i\\). It is likely that by changing \\(b_i\\) we change the optimal solution. But we would want this change to be differentiable. This can be achieved by requiring the set of basic and non-basic variables to remain unchanged. In this case, the equation (11.2) will still be the equation describing the dictionary at the optimal solution and the change in \\(b_i\\) will result in a differentiable (in fact, linear) change in \\(x_{\\mathcal{B}}\\). Example 11.2 Suppose we vary \\(b_3 = 1\\) in Example (1.2). One can check that at the optimal solution \\(w_1\\) and \\(w_2\\) are non-basic as long as \\(b_3 &gt; 0.9\\). Thus we can say that out model is a good model as long as the error in \\(b_3\\) is less than \\(0.1\\). Suppose we change \\(b_i\\) to \\(b_i + \\delta\\), where \\(\\delta\\) is a real number, and leave all the other constants unchanged. This is equivalent to changing \\(b\\) to \\(b + \\delta e_i\\) where \\(e_i\\) is the \\(i^{th}\\) standard basis vector. This changes equation (11.2) to \\[\\begin{align} x_{\\mathcal{B}} &amp;= \\mathcal{B}^{-1} b + \\delta \\mathcal{B}^{-1} e_i - \\mathcal{B}^{-1} \\mathcal{N} x_{\\mathcal{N}} \\\\ &amp;= \\mathcal{B}^{-1} b + \\delta (\\mathcal{B}^{-1})_{*i} - \\mathcal{B}^{-1} \\mathcal{N} x_{\\mathcal{N}}. \\end{align}\\] where \\((\\mathcal{B}^{-1})_{*i}\\) denotes the \\(i^{th}\\) column of \\(\\mathcal{B}^{-1}\\). Note that the coefficients of \\(x_{\\mathcal{N}}\\) remain unchanged. So, for this dictionary to stay optimal we only need the constants to remain non-negative i.e. \\[\\begin{equation} \\mathcal{B}^{-1} b + \\delta (\\mathcal{B}^{-1})_{*i} \\ge 0. \\tag{11.3} \\end{equation}\\] The range of optimality for \\(b_i\\) is the interval \\((b_i + \\delta_-, b_i + \\delta_+)\\) such that \\(\\mathcal{B}^{-1} b + \\delta (\\mathcal{B}^{-1})_{*i} \\ge 0\\) for all \\(\\delta \\in (\\delta_-, \\delta_+)\\). In practice, Equation (11.3) gives us \\(m\\) inequalities, all of which need to be simultaneously satisfied. These give us candidate values for \\(\\delta\\) some of which are positive and some of which are negative. We then choose \\(\\delta_+\\) to be the smallest positive value and \\(\\delta_-\\) to be the largest negative value. If \\(\\delta_+\\) does not exist the upper bound is \\(\\infty\\) and if \\(\\delta_-\\) does not exist the lower bound is \\(-\\infty\\). If either \\(\\delta_+\\) or \\(\\delta_-\\) is 0 then the linear program is degenerate and the range of optimality of \\(b_i\\) is empty. In this case, our program is very sensitive to perturbations in \\(b_i\\). Example 11.3 Let us find the range of optimality for \\(b_1 = 3.6\\), \\(b_2=1.5\\), and \\(b_3 = 1\\) in (1.2) using our calculations in Example 11.1. We know that \\[\\begin{align} \\mathcal{B}^{-1} = \\begin{bmatrix} -1/9 &amp; 2/3 &amp; 0 \\\\ 2/9 &amp; -1/3 &amp; 0 \\\\ -1/9 &amp; -1/3 &amp; 1 \\end{bmatrix}. \\end{align}\\] Using \\(i = 1\\) and Lemma 11.1 in Equation (11.3) we get \\[\\begin{align} \\begin{bmatrix} 0.6 \\\\ 0.3 \\\\ 0.9 \\end{bmatrix} + \\delta \\begin{bmatrix} -1/9 \\\\ 2/3 \\\\ -1/9 \\end{bmatrix} &gt; 0 \\end{align}\\] which gives us the inequalities \\[\\begin{align} \\begin{array}{llllllll} 0.6 + \\delta (-1/9) &amp;\\ge 0 &amp; \\implies &amp; \\delta &amp;\\le - 0.6 (9) = 5.4 \\\\ 0.3 + \\delta (2/9) &amp;\\ge 0 &amp; \\implies &amp; \\delta &amp;\\ge -0.3 (9/2) = -1.35 \\\\ 0.1 + \\delta (-1/9) &amp;\\ge 0 &amp; \\implies &amp; \\delta &amp; \\le 0.1 (9) = 0.9. \\end{array} \\end{align}\\] So, \\(\\delta_- = -1.35\\) and \\(\\delta_+ = \\min(5.4, 0.9) = 0.9\\) and the range of optimality of \\(b_1\\) is \\((3.6 - 1.35, 3.6 + 0.9) = (2.85, 3.45)\\). Using \\(i = 2\\) and Lemma 11.1 in Equation (11.3) we get \\[\\begin{align} \\begin{bmatrix} 0.6 \\\\ 0.3 \\\\ 0.9 \\end{bmatrix} + \\delta \\begin{bmatrix} 2/3 \\\\ -1/3 \\\\ -1/3 \\end{bmatrix} &gt; 0 \\end{align}\\] which gives us the inequalities \\[\\begin{align} \\begin{array}{llllllll} 0.6 + \\delta (2/3) &amp;\\ge 0 &amp; \\implies &amp; \\delta &amp;\\ge - 0.6 (3/2) = -0.9 \\\\ 0.3 + \\delta (-1/3) &amp;\\ge 0 &amp; \\implies &amp; \\delta &amp;\\le 0.3 (3) = 0.9 \\\\ 0.1 + \\delta (-1/3) &amp;\\ge 0 &amp; \\implies &amp; \\delta &amp; \\le 0.3 (1) = 0.3. \\end{array} \\end{align}\\] So, \\(\\delta_- = -0.9\\) and \\(\\delta_+ = \\min(0.3, 0.9) = 0.3\\) and the range of optimality of \\(b_2\\) is \\((1.5 - 0.9, 1.5 + 0.3) = (0.6, 1.8)\\). Using \\(i = 3\\) and Lemma 11.1 in Equation (11.3) we get \\[\\begin{align} \\begin{bmatrix} 0.6 \\\\ 0.3 \\\\ 0.1 \\end{bmatrix} + \\delta \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix} &gt; 0 \\end{align}\\] which gives us \\(\\delta \\ge -0.1\\) and so the range of optimality of \\(b_3\\) is \\((1 - 0.1, \\infty) = (0.9, \\infty)\\). 11.3 Rate of change Assume now that neither of \\(\\delta_+\\) or \\(\\delta_-\\) is zero. Then, we can use Lemma 11.1 to find the rate of change of the optimal solution with respect to \\(b_i\\). Call the objective function \\(\\mathbb{O} = c^{T} x\\). We think of \\(\\mathbb{O}\\) as being a function of \\(b_i\\), \\(c_j\\), and \\(a_{ij}.\\) Using Lemma 11.1 we get \\[\\begin{align} \\dfrac{\\partial x_{\\mathcal{B}_j}}{\\partial b_i} &amp;= j^{th} \\mbox{ row of } \\dfrac{\\partial \\mathcal{B}^{-1}b}{\\partial b_i} \\\\ &amp;= (\\mathcal{B}^{-1})_{ji} \\\\ \\end{align}\\] where \\(x_{\\mathcal{B}_j}\\) denotes the \\(j^{th}\\) basic variable and \\[\\begin{align} \\dfrac{\\partial x_{\\mathcal{N}}}{\\partial b_i} &amp;= 0 \\end{align}\\] as the non-basic variables remain 0 when we perturb \\(b_i\\) within the range of optimality. Using these we can find the rate of change of the optimal solution \\(\\mathbb{O}\\) with respect to \\(b_i\\). We first start by re-indexing the variables and objective coefficients using the basic and non-basic variables. \\[\\begin{align} \\mathbb{O} &amp;= c^T x \\\\ &amp;= c^T_{\\mathcal{B}} x_{\\mathcal{B}} + c^T_{\\mathcal{N}} x_{\\mathcal{N}} \\\\ \\implies \\dfrac{\\partial \\mathbb{O}}{\\partial b_i} &amp;= c^T_{\\mathcal{B}} \\dfrac{\\partial x_{\\mathcal{B}}}{\\partial b_i} + c^T_{\\mathcal{N}} \\dfrac{\\partial x_{\\mathcal{N}}}{\\partial b_i} \\\\ &amp;= c^T_{\\mathcal{B}} (\\mathcal{B}^{-1})_{*i} \\\\ \\end{align}\\] 11.4 Dual variables We saw above that this rate of change is exactly the dual optimal solution \\(y_i^*\\). Hence, we get \\[\\begin{align} y^*_i = c^T_{\\mathcal{B}} (\\mathcal{B}^{-1})_{*i}. \\end{align}\\] We can combine all the above coordinates into a single vector to get the following result. Theorem 11.1 For a non-degenerate linear program, the dual optimal solution is given by \\((\\mathcal{B}^{-1})^Tc_{\\mathcal{B}}\\). This theorem provides yet another method of finding the dual optimal solution without having to solve the dual linear program. Example 11.4 For the linear program (1.2), the objective function is \\[\\begin{align} \\mathbb{O} &amp; = 4 x + 3y \\\\ &amp; = 4x + 3y + 0 w_3 + 0 w_1 + 0 w_2 \\end{align}\\] So, \\(c_{\\mathcal{B}} = \\begin{bmatrix}4 \\\\ 3 \\\\ 0 \\end{bmatrix}\\) and \\(\\mathcal{N} = \\begin{bmatrix}0 \\\\ 0 \\end{bmatrix}\\). Using the value of \\(\\mathcal{B}^{-1}\\) calculated above, we get \\[\\begin{align} y^* &amp; = (\\mathcal{B}^{-1})^Tc_{\\mathcal{B}} \\\\ &amp; = \\begin{bmatrix} -1/9 &amp; 2/9 &amp; -1/9 \\\\ 2/3 &amp; -1/3 &amp; -1/3 \\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 4 \\\\ 3 \\\\ 0 \\end{bmatrix}\\\\ &amp; = \\begin{bmatrix} 2/9 \\\\ 5/3 \\\\ 0. \\end{bmatrix} \\end{align}\\] To check that this is indeed dual-optimal, we calculate the dual-objective value at this solution \\[\\begin{align} b^T y^* &amp; = 3.6 (2/9) + 1.5 (5/3) + 0 (1) \\\\ &amp;= 3.3 \\end{align}\\] which equals the optimal objective value of the primal. One can check that this solution is also dual-feasible and hence is the dual-optimal solution by Certificate of Optimality (Theorem 9.1). "],["sensitivity-analysis---objective.html", "Chapter 12 Sensitivity analysis - Objective", " Chapter 12 Sensitivity analysis - Objective We can ask the same questions as in the previous chapter about the change in the objective coefficients - how far can we change the objective coefficient \\(c_i\\) without changing the set of basic and non-basic variables at the optimal solution. Note that in this case we are not changing the constraints and therefore the feasible region. So, this is the same as asking - how far can we change the objective coefficient \\(c_i\\) without changing the optimal solution. We can redo the entire analysis for the objective coefficients from scratch. However, we also know the objective coefficients are the constraint upper bounds for the dual linear program and by Strong duality (Theorem 8.2) the primal and dual optimal objective values are the same. Thus performing sensitivity analysis on the objective coefficients of the primal is the same as performing sensitivity analysis on the constraints of the dual. Consider the standardized dual \\[\\begin{equation} \\begin{array}{lrll} \\mbox{minimize: } &amp; -b^T y \\\\ \\mbox{subject to: } &amp; -A^T y &amp; \\leq &amp; -c \\\\ &amp; y &amp; \\geq &amp; 0, \\end{array} \\end{equation}\\] Using Equation (11.3) for this dictionary we get the range of optimality for \\(-c_j\\) to be \\[\\begin{equation} (-\\mathcal{B}_d)^{-1} (-c) + \\delta (-\\mathcal{B}_d^{-1})_{*j} \\ge 0. \\end{equation}\\] where \\(\\mathcal{B}_d\\) is the basic submatrix of the standardized dual which simplifies to \\[\\begin{equation} \\mathcal{B}_d^{-1} c - \\delta (\\mathcal{B}_d^{-1})_{*j} \\ge 0. \\end{equation}\\] Note that this is the range of optimality for \\(-c_j\\). To get the range of optimality for \\(c_j\\) we need to replace \\(\\delta\\) by \\(-\\delta\\) to get \\[\\begin{equation} \\mathcal{B}_d^{-1} c + \\delta (\\mathcal{B}_d^{-1})_{*j} \\ge 0. \\end{equation}\\] Finally, by Lemma 11.1 \\(\\mathcal{B}_d^{-1} c\\) is the vector of values of the dual basic variables. Hence we get, the range of optimality for \\(c_j\\) is the interval \\((c_j + \\delta_-, c_j + \\delta_+)\\) such that \\(y_{\\mathcal{B}}^* + \\delta (\\mathcal{B}_d^{-1})_{*j} \\ge 0\\) for all \\(\\delta \\in (\\delta_-, \\delta_+)\\). Note that as a happy accident all the negative signs cancel out and the equation for finding the range of optimality for the objective coefficients is exactly the same as the one for finding the range of optimality for the constraints. ::: {theorem #range-of-optimality} The range of optimality for the constraints and the objective functions are given the following formulae: Range of optimality for \\(b_i\\): \\[\\begin{equation} x_{\\mathcal{B}}^* + \\delta (\\mathcal{B}^{-1})_{*i} \\ge 0. \\end{equation}\\] Range of optimality for \\(c_j\\): \\[\\begin{equation} y_{\\mathcal{B}}^* + \\delta (\\mathcal{B}_d^{-1})_{*j} \\ge 0. \\end{equation}\\] ::: "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]

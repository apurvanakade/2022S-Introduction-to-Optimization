# Sensitivity analysis - Constraints

Linear programs are used to model real world problems. Such models are at best approximate and at worst inaccurate. As such, it is important to understand the *sensitivity* of our solution to changes in the model. This is broadly called *sensitivity analysis*. We will focus on understanding the dependence of the optimal objective value of the standard linear program \@ref(eq:standard-lp) on the constants $b_i$ and $c_j$.

*Throughout this chapter, we'll assume that our linear programs have an optimal solution.*

## Matrix notation

In our previous analysis of the simplex method, we assumed that the constants $b_i$, $c_j$, and $a_{ij}$ were being dynamically updated. However, now we'll assume that they are fixed constants as our goal is no longer to run the simplex algorithm but rather to find the dependence of the solution on the initial values of these constants.

We will start by finding a succinct way to describe the dictionary at the optimal solution. Recall that the decision and slack variables are related to each other by the Equation \@ref(eq:standard-tableau) which can be written as:

\begin{equation}
  \begin{bmatrix} A & I_m \end{bmatrix}
    \begin{bmatrix} x \\ w \end{bmatrix}
      = b.
  (\#eq:dictionary-matrix)
\end{equation}

Let $\widehat{A} := \begin{bmatrix} A & I_m \end{bmatrix}$. We'll decompose $\widehat{A}$ using the basic and non-basic variables. Then let $\mathcal{B}$ be the matrix formed by combining the columns of $\widehat{A}$ corresponding to the basic variables and let $\mathcal{N}$ be the matrix formed by combining the columns of $\widehat{A}$ corresponding to the non-basic variables. Let $x_{\mathcal{B}}$ be the vector of basic variables and $x_{\mathcal{N}}$ be the vector of non-basic variables. 

By rearranging the columns of $\widehat{A}$ if necessary, we can rewrite \@ref(eq:dictionary-matrix) as 

\begin{align}
  && 
    \begin{bmatrix} \mathcal{B} & \mathcal{N} \end{bmatrix}
    \begin{bmatrix} x_{\mathcal{B}} \\ x_{\mathcal{N}} \end{bmatrix}
      &= b,\\
  \implies 
  &&
    \mathcal{B} x_{\mathcal{B}} + \mathcal{N} x_{\mathcal{N}} &= b, \\
  \implies
  &&
    \mathcal{B} x_{\mathcal{B}} &= b -  \mathcal{N} x_{\mathcal{N}}.
\end{align}

One can show that the matrix $\mathcal{B}$ is always invertible (hence the name "basic" variables) and the above equation can be further simplified to the following:
\begin{equation}
  x_{\mathcal{B}} = \mathcal{B}^{-1} b - \mathcal{B}^{-1} \mathcal{N} x_{\mathcal{N}}.
  (\#eq:basic-non-basic-matrix)
\end{equation}

This is nothing but the dictionary at the optimal solution.

::: {.example #basic-non-basic-matrix} 

Consider Example \@ref(eq:bond-portfolio-lp) again. At the optimal solution $w_1$ and $w_2$ are non-basic and have the value 0, and $x$, $y$, and $w_3$ are basic with values $0.3$, $0.6$, and $0.9$, respectively. Using the above notation, we have 

\begin{align}
  \mathcal{B} = 
    \begin{bmatrix}
    3 & 6 & 0 \\
    2 & 1 & 0 \\
    1 & 1 & 1
    \end{bmatrix}, 
  x_{\mathcal{B}} 
    = \begin{bmatrix} x \\ y \\ w_3 \end{bmatrix}, \\
  \mathcal{N} = 
    \begin{bmatrix}
    1 & 0 \\
    0 & 1 \\
    0 & 0
    \end{bmatrix}, 
  x_{\mathcal{N}}
    = \begin{bmatrix} w_1 \\ w_2 \end{bmatrix}.
\end{align}
Using Equation \@ref(eq:basic-non-basic-matrix) the dictionary at the optimal solution becomes 
\begin{align}
  \begin{bmatrix} x \\ y \\ w_3 \end{bmatrix} 
   &= \begin{bmatrix}
    3 & 6 & 0 \\
    2 & 1 & 0 \\
    1 & 1 & 1
    \end{bmatrix}^{-1} 
    \begin{bmatrix}
    3.6 \\ 1.5 \\ 1 
    \end{bmatrix} - 
    \begin{bmatrix}
    3 & 6 & 0 \\
    2 & 1 & 0 \\
    1 & 1 & 1
    \end{bmatrix}^{-1} \begin{bmatrix}
    1 & 0 \\
    0 & 1 \\
    0 & 0
    \end{bmatrix}
  \begin{bmatrix} w_1 \\ w_2 \end{bmatrix} \\
  & = \begin{bmatrix}
    -1/9 & 2/3 & 0 \\
    2/9 & -1/3 & 0 \\
    -1/9 & -1/3 & 1
    \end{bmatrix} 
    \begin{bmatrix}
    3.6 \\ 1.5 \\ 1 
    \end{bmatrix} - 
    \begin{bmatrix}
    -1/9 & 2/3 & 0 \\
    2/9 & -1/3 & 0 \\
    -1/9 & -1/3 & 1
    \end{bmatrix}  
    \begin{bmatrix}
    1 & 0 \\
    0 & 1 \\
    0 & 0
    \end{bmatrix}
  \begin{bmatrix} w_1 \\ w_2 \end{bmatrix} \\
  & 
  = \begin{bmatrix} 0.6 \\ 0.3 \\ 0.1 \end{bmatrix} 
  -
  \begin{bmatrix}
    -1/9 & 2/3 \\ 
    2/9 & -1/3 \\
    -1/9 & -1/3
  \end{bmatrix}
  \begin{bmatrix} w_1 \\ w_2 \end{bmatrix}.
\end{align}

This is precisely the dictionary \@ref(eq:example-dictionary-3) at the optimal solution.
:::

Because we set the non-basic variables $x_{\mathcal{N}}$ to 0 at any vertex, and in particular, at the the optimal solution, using the Equation \@ref(eq:basic-non-basic-matrix) we get the following useful result:

::: {.lemma #basic-values}

Using the above notation, $\mathcal{B}^{-1}b$ is the value of the basic variables $x^*_{\mathcal{B}}$ at the optimal solution.

:::


## Range of optimality 

We now try to determine the change in optimal solution as we change the constraint upper bounds $b_i$. It is likely that by changing $b_i$ we change the optimal solution. But we would want this change to be differentiable. This can be achieved by requiring the set of basic and non-basic variables to remain unchanged. In this case, the equation \@ref(eq:basic-non-basic-matrix) will still be the equation describing the dictionary at the optimal solution and the change in $b_i$ will result in a differentiable (in fact, linear) change in $x_{\mathcal{B}}$.

::: {.example}

Suppose we vary $b_3 = 1$ in Example \@ref(eq:bond-portfolio-lp). One can check that at the optimal solution $w_1$ and $w_2$ are non-basic as long as $b_3 > 0.9$. Thus we can say that out model is a good model as long as the error in $b_3$ is less than $0.1$.

:::

Suppose we change $b_i$ to $b_i + \delta$, where $\delta$ is a real number, and leave all the other constants unchanged. This is equivalent to changing $b$ to $b + \delta e_i$ where $e_i$ is the $i^{th}$ standard basis vector. This changes equation \@ref(eq:basic-non-basic-matrix) to 

\begin{align}
  x_{\mathcal{B}} 
    &= \mathcal{B}^{-1} b + \delta \mathcal{B}^{-1} e_i - \mathcal{B}^{-1} \mathcal{N} x_{\mathcal{N}} \\
    &= \mathcal{B}^{-1} b + \delta (\mathcal{B}^{-1})_{\_i} - \mathcal{B}^{-1} \mathcal{N} x_{\mathcal{N}}.
\end{align}
where $(\mathcal{B}^{-1})_{\_i}$ denotes the $i^{th}$ column of $\mathcal{B}^{-1}$.

Note that the coefficients of $x_{\mathcal{N}}$ remain unchanged. So, for this dictionary to stay optimal we only need the constants to remain non-negative i.e.

\begin{equation}
  \mathcal{B}^{-1} b + \delta (\mathcal{B}^{-1})_{\_i} \ge 0.
  (\#eq:range-of-optimality)
\end{equation}


The **range of optimality** for $b_i$ is the interval $(b_i + \delta_-, b_i + \delta_+)$ such that $\mathcal{B}^{-1} b + \delta (\mathcal{B}^{-1})_{\_i} \ge 0$ for all $\delta \in (\delta_-, \delta_+)$.

In practice, Equation \@ref(eq:range-of-optimality) gives us $m$ inequalities, all of which need to be simultaneously satisfied. These give us candidate values for $\delta$ some of which are positive and some of which are negative. We then choose $\delta_+$ to be the smallest positive value and $\delta_-$ to be the largest negative value. If $\delta_+$ does not exist the upper bound is $\infty$ and if $\delta_-$ does not exist the lower bound is $-\infty$. If either $\delta_+$ or $\delta_-$ is 0 then the linear program is degenerate and the range of optimality for $b_i$ is empty. In this case, our program is very sensitive to perturbations in $b_i$.


::: {.example}

Let us find the range of optimality for $b_1 = 3.6$, $b_2=1.5$, and $b_3 = 1$ in \@ref(eq:bond-portfolio-lp) using our calculations in Example \@ref(exm:basic-non-basic-matrix).

We know that 
\begin{align}
  \mathcal{B}^{-1} = 
    \begin{bmatrix}
    -1/9 & 2/3 & 0 \\
    2/9 & -1/3 & 0 \\
    -1/9 & -1/3 & 1
    \end{bmatrix}.
\end{align}


Using $i = 1$ and Lemma \@ref(lem:basic-values) in Equation \@ref(eq:range-of-optimality) we get

\begin{align}
  \begin{bmatrix} 0.6 \\ 0.3 \\ 0.1 \end{bmatrix} 
  + \delta
  \begin{bmatrix}
    -1/9 \\ 
    2/9 \\
    -1/9
  \end{bmatrix} > 0
\end{align}

which gives us the inequalities 

\begin{align}
  \begin{array}{lrlrrll}
    0.6 + \delta (-1/9) &\ge & 0 & \implies & \delta &\le & 0.6 (9) = 5.4 \\
    0.3 + \delta (2/9) &\ge & 0 & \implies & \delta &\ge & -0.3 (9/2) = -1.35  \\
    0.1 + \delta (-1/9) &\ge & 0 & \implies & \delta & \le & 0.1 (9) = 0.9.  
  \end{array}
\end{align}

So, $\delta_- = -1.35$ and $\delta_+ = \min(5.4, 0.9) = 0.9$ and the range of optimality for $b_1$ is $(3.6 - 1.35, 3.6 + 0.9) = (2.85, 3.45)$.

Using $i = 2$ and Lemma \@ref(lem:basic-values) in Equation \@ref(eq:range-of-optimality) we get

\begin{align}
  \begin{bmatrix} 0.6 \\ 0.3 \\ 0.1 \end{bmatrix} 
  + \delta
  \begin{bmatrix}
    2/3 \\ 
    -1/3 \\
    -1/3
  \end{bmatrix} > 0
\end{align}

which gives us the inequalities 

\begin{align}
  \begin{array}{lrlrrll}
    0.6 + \delta (2/3) &\ge& 0 & \implies & \delta &\ge& - 0.6 (3/2) = -0.9 \\
    0.3 + \delta (-1/3) &\ge &0 & \implies & \delta &\le &0.3 (3) = 0.9  \\
    0.1 + \delta (-1/3) &\ge &0 & \implies & \delta & \le& 0.3 (1) = 0.3.  
  \end{array}
\end{align}

So, $\delta_- = -0.9$ and $\delta_+ = \min(0.3, 0.9) = 0.3$ and the range of optimality for $b_2$ is $(1.5 - 0.9, 1.5 + 0.3) = (0.6, 1.8)$.

Using $i = 3$ and Lemma \@ref(lem:basic-values) in Equation \@ref(eq:range-of-optimality) we get

\begin{align}
  \begin{bmatrix} 0.6 \\ 0.3 \\ 0.1 \end{bmatrix} 
  + \delta
  \begin{bmatrix}
    0 \\ 
    0 \\
    1
  \end{bmatrix} > 0
\end{align}

which gives us $\delta \ge -0.1$ and so the range of optimality for $b_3$ is $(1 - 0.1, \infty) = (0.9, \infty)$.

:::



## Rate of change

Assume now that neither of $\delta_+$ or $\delta_-$ is zero. Then, we can use Lemma \@ref(lem:basic-values) to find the rate of change of the optimal solution with respect to $b_i$. Call the objective function $\mathbb{O} = c^{T} x^*$. We think of $\mathbb{O}$ as being a function of $b_i$, $c_j$, and $a_{ij}.$ Using Lemma \@ref(lem:basic-values) we get

\begin{align}
  \dfrac{\partial x^*_{\mathcal{B}_j}}{\partial b_i} 
    &= j^{th} \mbox{ row of } \dfrac{\partial \mathcal{B}^{-1}b}{\partial b_i} \\
    &= (\mathcal{B}^{-1})_{ji} \\
\end{align}
where $x^*_{\mathcal{B}_j}$ denotes the $j^{th}$ basic variable at the optimal solution and 
\begin{align}
  \dfrac{\partial x^*_{\mathcal{N}}}{\partial b_i} 
    &= 0
\end{align}
as the non-basic variables remain 0 when we perturb $b_i$ within the range of optimality.
Using these we can find the rate of change of the optimal solution $\mathbb{O}$ with respect to $b_i$. We first start by re-indexing the variables and objective coefficients using the basic and non-basic variables. 

\begin{align}
  \mathbb{O} 
    &= c^T x^* \\
    &= c^T_{\mathcal{B}} x^*_{\mathcal{B}} + c^T_{\mathcal{N}} x^*_{\mathcal{N}} \\
\implies
  \dfrac{\partial \mathbb{O}}{\partial b_i} 
    &= c^T_{\mathcal{B}} \dfrac{\partial x^*_{\mathcal{B}}}{\partial b_i} + c^T_{\mathcal{N}} \dfrac{\partial x^*_{\mathcal{N}}}{\partial b_i} \\
    &= c^T_{\mathcal{B}} (\mathcal{B}^{-1})_{\_i} \\
\end{align}


## Dual variables

We saw above that this rate of change is exactly the dual optimal solution $y_i^*$. Hence, we get 
\begin{align}
  y^*_i = c^T_{\mathcal{B}} (\mathcal{B}^{-1})_{\_i}.
\end{align}

We can combine all the above coordinates into a single vector to get the following result.

::: {.theorem #dual-solution}

For a non-degenerate linear program, the dual optimal solution is given by $(\mathcal{B}^{-1})^Tc_{\mathcal{B}}$.

:::

This theorem provides yet another method of finding the dual optimal solution without having to solve the dual linear program. 

::: {.example #dual-solution} 
For the linear program \@ref(eq:bond-portfolio-lp), the objective function is 

\begin{align}
  \mathbb{O} & = 4 x + 3y \\
  & = 4x + 3y + 0 w_3 + 0 w_1 + 0 w_2 
\end{align}

So, $c_{\mathcal{B}} = \begin{bmatrix}4 \\ 3 \\ 0 \end{bmatrix}$ and $\mathcal{N} = \begin{bmatrix}0 \\ 0 \end{bmatrix}$. Using the value of $\mathcal{B}^{-1}$ calculated above, we get 

\begin{align}
  y^* & = (\mathcal{B}^{-1})^Tc_{\mathcal{B}} \\
  & = 
    \begin{bmatrix}
    -1/9 & 2/9 & -1/9 \\
    2/3 & -1/3 & -1/3 \\
    0 & 0 & 1
    \end{bmatrix} 
    \begin{bmatrix}
      4 \\ 3 \\ 0
    \end{bmatrix}\\
  & = 
  \begin{bmatrix}
    2/9 \\ 5/3 \\ 0
  \end{bmatrix}.
\end{align}

To check that this is indeed dual-optimal, we calculate the dual-objective value at this solution

\begin{align}
  b^T y^* & = 3.6 (2/9) + 1.5 (5/3) + 0 (1) \\
  &= 3.3
\end{align}

which equals the optimal objective value of the primal. One can check that this solution is also dual-feasible and hence is the dual-optimal solution by Certificate of Optimality (Theorem \@ref(thm:certificate-of-optimality)).

:::


